{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11999607,"sourceType":"datasetVersion","datasetId":7548337}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nmidi_count = 0\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if filename.lower().endswith('.mid'):\n            midi_count += 1\n\nprint(f\"Total number of MIDI files: {midi_count}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:14.038766Z","iopub.execute_input":"2025-06-03T18:20:14.039003Z","iopub.status.idle":"2025-06-03T18:20:22.259302Z","shell.execute_reply.started":"2025-06-03T18:20:14.038979Z","shell.execute_reply":"2025-06-03T18:20:22.258710Z"}},"outputs":[{"name":"stdout","text":"Total number of MIDI files: 3896\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\n!pip install music21 torch pretty_midi tqdm --quiet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:20:24.782517Z","iopub.execute_input":"2025-06-03T18:20:24.783059Z","iopub.status.idle":"2025-06-03T18:21:46.741275Z","shell.execute_reply.started":"2025-06-03T18:20:24.783034Z","shell.execute_reply":"2025-06-03T18:21:46.740595Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\nimport os\nimport music21\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport pretty_midi\nimport pickle\nfrom torch.utils.data import Dataset, DataLoader\nfrom pathlib import Path\nimport random\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:22:20.160229Z","iopub.execute_input":"2025-06-03T18:22:20.160516Z","iopub.status.idle":"2025-06-03T18:22:24.699388Z","shell.execute_reply.started":"2025-06-03T18:22:20.160489Z","shell.execute_reply":"2025-06-03T18:22:24.698825Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"midi_dir = Path(\"/kaggle/input/nintendo-midis/Nintendo\")\nchord_vocab, melody_vocab = {}, {}\nchord_seqs, melody_seqs = [], []\n\nmax_len = 64\nmax_files = 4000\nmidi_files = list(midi_dir.rglob(\"*.mid\"))\nrandom.shuffle(midi_files)\n\n\ndef note_to_int(note):\n    return int(note.pitch.midi)\n\ndef chord_to_label(chord):\n    root = chord.root().name\n    quality = chord.quality\n    return f\"{root}_{quality}\"\n\nfor file in tqdm(midi_files[:max_files], desc=\"Processing MIDI files\"):\n    try:\n        score = music21.converter.parse(file)\n        if isinstance(score, music21.stream.Opus):\n            if len(score.scores) == 0:\n                continue\n            score = score.scores[0]\n\n        chords = score.chordify().flatten().getElementsByClass('Chord')\n        melody = score.parts[0].flatten().getElementsByClass('Note')\n\n        chord_seq = []\n        for c in chords[:max_len]:\n            label = chord_to_label(c)\n            if label not in chord_vocab:\n                chord_vocab[label] = len(chord_vocab)\n            chord_seq.append(chord_vocab[label])\n\n        melody_seq = []\n        for n in melody[:max_len]:\n            midi = note_to_int(n)\n            if midi not in melody_vocab:\n                melody_vocab[midi] = len(melody_vocab)\n            melody_seq.append(melody_vocab[midi])\n\n        if len(chord_seq) == len(melody_seq) == max_len:\n            chord_seqs.append(chord_seq)\n            melody_seqs.append(melody_seq)\n    except Exception as e:\n        print(f\"Failed on {file}: {e}\")\n\nwith open(\"processed.pkl\", \"wb\") as f:\n    pickle.dump({\n        \"chord_seqs\": chord_seqs,\n        \"melody_seqs\": melody_seqs,\n        \"chord_vocab\": chord_vocab,\n        \"melody_vocab\": melody_vocab\n    }, f)\n\nprint(f\"Saved Nintendo MIDI sequences.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T18:22:26.729548Z","iopub.execute_input":"2025-06-03T18:22:26.729937Z","iopub.status.idle":"2025-06-03T19:37:19.163235Z","shell.execute_reply.started":"2025-06-03T18:22:26.729914Z","shell.execute_reply":"2025-06-03T19:37:19.162625Z"}},"outputs":[{"name":"stderr","text":"Processing MIDI files:  86%|████████▌ | 3347/3896 [1:03:55<06:00,  1.52it/s] ","output_type":"stream"},{"name":"stdout","text":"Failed on /kaggle/input/nintendo-midis/Nintendo/3DS/FireEmblemAwakening/.mid: cannot find a format extensions for: /kaggle/input/nintendo-midis/Nintendo/3DS/FireEmblemAwakening/.mid\n","output_type":"stream"},{"name":"stderr","text":"Processing MIDI files: 100%|██████████| 3896/3896 [1:14:50<00:00,  1.15s/it]  ","output_type":"stream"},{"name":"stdout","text":"Saved Nintendo MIDI sequences.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"class ChordMelodyDataset(Dataset):\n    def __init__(self, X, Y, seq_len):\n        self.X = X\n        self.Y = Y\n        self.seq_len = seq_len\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        return (\n            torch.tensor(self.X[idx][:self.seq_len]),\n            torch.tensor(self.Y[idx][:self.seq_len])\n        )\n\nclass ChordToMelodyLSTM(nn.Module):\n    def __init__(self, chord_vocab, melody_vocab, hidden_dim=128):\n        super().__init__()\n        self.chord_embed = nn.Embedding(chord_vocab, hidden_dim)\n        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n        self.attn = nn.MultiheadAttention(embed_dim=hidden_dim*2, num_heads=2, batch_first=True)\n        self.out = nn.Sequential(\n            nn.Linear(hidden_dim*2, hidden_dim*2),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(hidden_dim*2, melody_vocab)\n        )\n\n    def forward(self, chords):\n        x = self.chord_embed(chords)\n        h, _ = self.lstm(x)\n        attn_output, _ = self.attn(h, h, h)\n        return self.out(attn_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T19:37:57.149221Z","iopub.execute_input":"2025-06-03T19:37:57.149497Z","iopub.status.idle":"2025-06-03T19:37:57.156771Z","shell.execute_reply.started":"2025-06-03T19:37:57.149475Z","shell.execute_reply":"2025-06-03T19:37:57.155987Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"with open(\"processed.pkl\", \"rb\") as f:\n    data = pickle.load(f)\n\nchord_seqs = data[\"chord_seqs\"]\nmelody_seqs = data[\"melody_seqs\"]\nchord_vocab_size = len(data[\"chord_vocab\"])\nmelody_vocab_size = len(data[\"melody_vocab\"])\n\nseq_len = 64\n\nfiltered_pairs = [\n    (c, m) for c, m in zip(chord_seqs, melody_seqs)\n    if len(c) == seq_len and len(m) == seq_len\n]\n\nchord_seqs, melody_seqs = zip(*filtered_pairs) if filtered_pairs else ([], [])\n\ndataset = ChordMelodyDataset(chord_seqs, melody_seqs, seq_len)\nloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\nmodel = ChordToMelodyLSTM(chord_vocab_size, melody_vocab_size)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\nfor epoch in range(100):\n    total_loss = 0\n    for chords, melody in loader:\n        logits = model(chords)\n        loss = criterion(logits.view(-1, melody_vocab_size), melody.view(-1))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    print(f\"Epoch {epoch}: Loss = {total_loss:.4f}\")\n\ntorch.save(model.state_dict(), \"lstm_model.pt\")\nprint(\"Model saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T19:47:55.946546Z","iopub.execute_input":"2025-06-03T19:47:55.947190Z","iopub.status.idle":"2025-06-03T20:09:23.552417Z","shell.execute_reply.started":"2025-06-03T19:47:55.947159Z","shell.execute_reply":"2025-06-03T20:09:23.551601Z"}},"outputs":[{"name":"stdout","text":"Epoch 0: Loss = 406.9728\nEpoch 1: Loss = 389.3077\nEpoch 2: Loss = 384.3761\nEpoch 3: Loss = 381.5696\nEpoch 4: Loss = 379.4148\nEpoch 5: Loss = 377.0618\nEpoch 6: Loss = 375.1254\nEpoch 7: Loss = 373.1363\nEpoch 8: Loss = 370.9506\nEpoch 9: Loss = 368.5528\nEpoch 10: Loss = 366.4501\nEpoch 11: Loss = 363.3060\nEpoch 12: Loss = 360.6589\nEpoch 13: Loss = 356.9566\nEpoch 14: Loss = 353.0570\nEpoch 15: Loss = 350.1042\nEpoch 16: Loss = 345.1470\nEpoch 17: Loss = 340.0254\nEpoch 18: Loss = 334.5153\nEpoch 19: Loss = 329.3661\nEpoch 20: Loss = 324.8503\nEpoch 21: Loss = 320.3435\nEpoch 22: Loss = 316.0900\nEpoch 23: Loss = 311.9285\nEpoch 24: Loss = 307.3275\nEpoch 25: Loss = 304.0875\nEpoch 26: Loss = 301.2781\nEpoch 27: Loss = 298.1860\nEpoch 28: Loss = 295.4268\nEpoch 29: Loss = 293.0991\nEpoch 30: Loss = 291.3836\nEpoch 31: Loss = 288.7888\nEpoch 32: Loss = 287.0538\nEpoch 33: Loss = 285.4287\nEpoch 34: Loss = 283.1119\nEpoch 35: Loss = 282.0360\nEpoch 36: Loss = 280.5579\nEpoch 37: Loss = 278.5476\nEpoch 38: Loss = 276.7181\nEpoch 39: Loss = 275.9516\nEpoch 40: Loss = 274.6055\nEpoch 41: Loss = 273.3233\nEpoch 42: Loss = 272.5271\nEpoch 43: Loss = 270.6955\nEpoch 44: Loss = 269.0368\nEpoch 45: Loss = 268.4290\nEpoch 46: Loss = 267.0630\nEpoch 47: Loss = 266.3813\nEpoch 48: Loss = 265.4609\nEpoch 49: Loss = 263.9319\nEpoch 50: Loss = 263.2186\nEpoch 51: Loss = 261.9434\nEpoch 52: Loss = 261.2921\nEpoch 53: Loss = 260.6654\nEpoch 54: Loss = 259.9162\nEpoch 55: Loss = 258.4924\nEpoch 56: Loss = 257.1713\nEpoch 57: Loss = 256.6409\nEpoch 58: Loss = 255.9769\nEpoch 59: Loss = 255.0781\nEpoch 60: Loss = 254.0613\nEpoch 61: Loss = 253.3039\nEpoch 62: Loss = 252.6800\nEpoch 63: Loss = 251.5569\nEpoch 64: Loss = 251.6106\nEpoch 65: Loss = 250.9245\nEpoch 66: Loss = 249.3661\nEpoch 67: Loss = 248.8496\nEpoch 68: Loss = 248.2834\nEpoch 69: Loss = 247.6605\nEpoch 70: Loss = 247.5775\nEpoch 71: Loss = 246.4279\nEpoch 72: Loss = 245.5255\nEpoch 73: Loss = 245.2115\nEpoch 74: Loss = 244.6270\nEpoch 75: Loss = 244.1788\nEpoch 76: Loss = 243.5476\nEpoch 77: Loss = 242.4256\nEpoch 78: Loss = 242.3682\nEpoch 79: Loss = 241.4820\nEpoch 80: Loss = 241.2470\nEpoch 81: Loss = 240.3540\nEpoch 82: Loss = 239.9490\nEpoch 83: Loss = 239.3345\nEpoch 84: Loss = 239.3392\nEpoch 85: Loss = 238.1482\nEpoch 86: Loss = 238.0056\nEpoch 87: Loss = 237.4316\nEpoch 88: Loss = 237.2836\nEpoch 89: Loss = 236.8157\nEpoch 90: Loss = 236.2210\nEpoch 91: Loss = 235.1051\nEpoch 92: Loss = 234.9637\nEpoch 93: Loss = 234.4736\nEpoch 94: Loss = 233.9708\nEpoch 95: Loss = 232.9753\nEpoch 96: Loss = 232.9880\nEpoch 97: Loss = 233.1432\nEpoch 98: Loss = 232.0590\nEpoch 99: Loss = 232.3283\nModel saved!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def generate_midi(melody_ids, melody_vocab, filename=\"generated.mid\"):\n    inv_vocab = {v: k for k, v in melody_vocab.items()}\n    pm = pretty_midi.PrettyMIDI()\n    inst = pretty_midi.Instrument(program=0)\n    for i, idx in enumerate(melody_ids):\n        pitch = inv_vocab.get(idx, 60)\n        note = pretty_midi.Note(\n            velocity=100, pitch=pitch, start=i*0.5, end=(i+1)*0.5\n        )\n        inst.notes.append(note)\n    pm.instruments.append(inst)\n    pm.write(filename)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T20:11:49.848600Z","iopub.execute_input":"2025-06-03T20:11:49.848906Z","iopub.status.idle":"2025-06-03T20:11:49.854327Z","shell.execute_reply.started":"2025-06-03T20:11:49.848887Z","shell.execute_reply":"2025-06-03T20:11:49.853589Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def sample_logits(logits, temperature=1.0):\n    probs = torch.softmax(logits / temperature, dim=-1)\n    return torch.multinomial(probs, num_samples=1)\n\ndef generate_from_model(model, chord_sequence, melody_vocab, device=\"cpu\", temperature=1.0):\n    model.eval()\n    with torch.no_grad():\n        chords = torch.tensor(chord_sequence).unsqueeze(0).to(device)\n        logits = model(chords).squeeze(0)\n        sampled = [sample_logits(logits[i], temperature).item() for i in range(logits.size(0))]\n        return sampled\n\nmodel.load_state_dict(torch.load(\"lstm_model.pt\"))\nmodel.eval()\n\nnintendo_intro = [data[\"chord_vocab\"].get(label) for label in [\n    \"C_major\", \"F_major\", \"G_major\", \"C_major\"\n]]\n\n\nnintendo_intro = [c if c is not None else 0 for c in nintendo_intro] + [0] * (64 - 16)\n\ngenerated_ids = generate_from_model(model, nintendo_intro, data[\"melody_vocab\"], temperature=0.8)\ngenerate_midi(generated_ids, data[\"melody_vocab\"], \"generate_final_res.mid\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-03T20:12:01.576725Z","iopub.execute_input":"2025-06-03T20:12:01.577200Z","iopub.status.idle":"2025-06-03T20:12:01.643892Z","shell.execute_reply.started":"2025-06-03T20:12:01.577177Z","shell.execute_reply":"2025-06-03T20:12:01.643168Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}