{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11999607,"sourceType":"datasetVersion","datasetId":7548337}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nmidi_count = 0\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if filename.lower().endswith('.mid'):\n            midi_count += 1\n\nprint(f\"Total number of MIDI files: {midi_count}\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-01T05:40:01.710955Z","iopub.execute_input":"2025-06-01T05:40:01.711594Z","iopub.status.idle":"2025-06-01T05:40:10.674469Z","shell.execute_reply.started":"2025-06-01T05:40:01.711568Z","shell.execute_reply":"2025-06-01T05:40:10.673860Z"}},"outputs":[{"name":"stdout","text":"Total number of MIDI files: 3896\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ğŸ“¦ 1. Install dependencies\n!pip install music21 torch pretty_midi tqdm --quiet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T17:13:41.082061Z","iopub.execute_input":"2025-06-01T17:13:41.082323Z","iopub.status.idle":"2025-06-01T17:15:14.594998Z","shell.execute_reply.started":"2025-06-01T17:13:41.082300Z","shell.execute_reply":"2025-06-01T17:15:14.594231Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for pretty_midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ğŸ“š 2. Import libraries\nimport os\nimport music21\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport pretty_midi\nimport pickle\nfrom torch.utils.data import Dataset, DataLoader\nfrom pathlib import Path\nimport random\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T17:15:14.596753Z","iopub.execute_input":"2025-06-01T17:15:14.597000Z","iopub.status.idle":"2025-06-01T17:15:21.537312Z","shell.execute_reply.started":"2025-06-01T17:15:14.596977Z","shell.execute_reply":"2025-06-01T17:15:21.536760Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ğŸ” 3. Recursively preprocess a subset of Nintendo MIDI files\nmidi_dir = Path(\"/kaggle/input/nintendo-midis/Nintendo\")\nchord_vocab, melody_vocab = {}, {}\nchord_seqs, melody_seqs = [], []\n\nmax_len = 64  # Increased length for longer melodies\nmax_files = 500  # Limit to avoid timeout\nmidi_files = list(midi_dir.rglob(\"*.mid\"))\nrandom.shuffle(midi_files)\n\n\ndef note_to_int(note):\n    return int(note.pitch.midi)\n\ndef chord_to_label(chord):\n    root = chord.root().name\n    quality = chord.quality\n    return f\"{root}_{quality}\"\n\nfor file in tqdm(midi_files[:max_files], desc=\"Processing MIDI files\"):\n    try:\n        score = music21.converter.parse(file)\n        if isinstance(score, music21.stream.Opus):\n            if len(score.scores) == 0:\n                continue\n            score = score.scores[0]\n\n        chords = score.chordify().flatten().getElementsByClass('Chord')\n        melody = score.parts[0].flatten().getElementsByClass('Note')\n\n        chord_seq = []\n        for c in chords[:max_len]:\n            label = chord_to_label(c)\n            if label not in chord_vocab:\n                chord_vocab[label] = len(chord_vocab)\n            chord_seq.append(chord_vocab[label])\n\n        melody_seq = []\n        for n in melody[:max_len]:\n            midi = note_to_int(n)\n            if midi not in melody_vocab:\n                melody_vocab[midi] = len(melody_vocab)\n            melody_seq.append(melody_vocab[midi])\n\n        if len(chord_seq) == len(melody_seq) == max_len:\n            chord_seqs.append(chord_seq)\n            melody_seqs.append(melody_seq)\n    except Exception as e:\n        print(f\"Failed on {file}: {e}\")\n\nwith open(\"processed.pkl\", \"wb\") as f:\n    pickle.dump({\n        \"chord_seqs\": chord_seqs,\n        \"melody_seqs\": melody_seqs,\n        \"chord_vocab\": chord_vocab,\n        \"melody_vocab\": melody_vocab\n    }, f)\n\nprint(f\"âœ… Saved {len(chord_seqs)} Nintendo MIDI sequences.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T17:16:27.629166Z","iopub.execute_input":"2025-06-01T17:16:27.629465Z","iopub.status.idle":"2025-06-01T17:24:43.052940Z","shell.execute_reply.started":"2025-06-01T17:16:27.629442Z","shell.execute_reply":"2025-06-01T17:24:43.052283Z"}},"outputs":[{"name":"stderr","text":"Processing MIDI files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [08:03<00:00,  1.03it/s]","output_type":"stream"},{"name":"stdout","text":"âœ… Saved 424 Nintendo MIDI sequences.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ğŸ§  4. Define dataset and LSTM model\nclass ChordMelodyDataset(Dataset):\n    def __init__(self, X, Y, seq_len):\n        self.X = X\n        self.Y = Y\n        self.seq_len = seq_len\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        return (\n            torch.tensor(self.X[idx][:self.seq_len]),\n            torch.tensor(self.Y[idx][:self.seq_len])\n        )\n\nclass ChordToMelodyLSTM(nn.Module):\n    def __init__(self, chord_vocab, melody_vocab, hidden_dim=128):\n        super().__init__()\n        self.chord_embed = nn.Embedding(chord_vocab, hidden_dim)\n        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n        self.attn = nn.MultiheadAttention(embed_dim=hidden_dim*2, num_heads=2, batch_first=True)\n        self.out = nn.Sequential(\n            nn.Linear(hidden_dim*2, hidden_dim*2),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(hidden_dim*2, melody_vocab)\n        )\n\n    def forward(self, chords):\n        x = self.chord_embed(chords)\n        h, _ = self.lstm(x)\n        attn_output, _ = self.attn(h, h, h)\n        return self.out(attn_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T17:49:58.364308Z","iopub.execute_input":"2025-06-01T17:49:58.364833Z","iopub.status.idle":"2025-06-01T17:49:58.371946Z","shell.execute_reply.started":"2025-06-01T17:49:58.364811Z","shell.execute_reply":"2025-06-01T17:49:58.371172Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# ğŸš€ 5. Train model\nwith open(\"processed.pkl\", \"rb\") as f:\n    data = pickle.load(f)\n\nchord_seqs = data[\"chord_seqs\"]\nmelody_seqs = data[\"melody_seqs\"]\nchord_vocab_size = len(data[\"chord_vocab\"])\nmelody_vocab_size = len(data[\"melody_vocab\"])\n\nseq_len = 64  # Match new max_len\n# Filter out sequences that don't match the required seq_len\nfiltered_pairs = [\n    (c, m) for c, m in zip(chord_seqs, melody_seqs)\n    if len(c) == seq_len and len(m) == seq_len\n]\nprint(len(filtered_pairs))\nchord_seqs, melody_seqs = zip(*filtered_pairs) if filtered_pairs else ([], [])\n\ndataset = ChordMelodyDataset(chord_seqs, melody_seqs, seq_len)\nloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\nmodel = ChordToMelodyLSTM(chord_vocab_size, melody_vocab_size)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\nfor epoch in range(200):\n    total_loss = 0\n    for chords, melody in loader:\n        logits = model(chords)\n        loss = criterion(logits.view(-1, melody_vocab_size), melody.view(-1))\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    print(f\"Epoch {epoch}: Loss = {total_loss:.4f}\")\n\ntorch.save(model.state_dict(), \"lstm_model.pt\")\nprint(\"âœ… Model saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T17:49:59.848447Z","iopub.execute_input":"2025-06-01T17:49:59.848757Z","iopub.status.idle":"2025-06-01T17:52:31.313332Z","shell.execute_reply.started":"2025-06-01T17:49:59.848727Z","shell.execute_reply":"2025-06-01T17:52:31.312500Z"}},"outputs":[{"name":"stdout","text":"424\nEpoch 0: Loss = 59.1663\nEpoch 1: Loss = 55.8764\nEpoch 2: Loss = 54.6162\nEpoch 3: Loss = 53.4292\nEpoch 4: Loss = 52.7463\nEpoch 5: Loss = 52.1071\nEpoch 6: Loss = 51.8705\nEpoch 7: Loss = 51.2955\nEpoch 8: Loss = 50.8954\nEpoch 9: Loss = 50.4553\nEpoch 10: Loss = 50.0312\nEpoch 11: Loss = 49.8846\nEpoch 12: Loss = 49.3610\nEpoch 13: Loss = 48.6861\nEpoch 14: Loss = 48.4739\nEpoch 15: Loss = 47.8643\nEpoch 16: Loss = 47.1622\nEpoch 17: Loss = 46.9429\nEpoch 18: Loss = 46.0541\nEpoch 19: Loss = 46.0170\nEpoch 20: Loss = 44.7660\nEpoch 21: Loss = 44.4209\nEpoch 22: Loss = 44.0563\nEpoch 23: Loss = 43.5063\nEpoch 24: Loss = 42.7152\nEpoch 25: Loss = 42.1174\nEpoch 26: Loss = 41.8610\nEpoch 27: Loss = 41.6130\nEpoch 28: Loss = 41.0867\nEpoch 29: Loss = 40.5823\nEpoch 30: Loss = 39.9292\nEpoch 31: Loss = 39.4418\nEpoch 32: Loss = 39.1415\nEpoch 33: Loss = 39.1981\nEpoch 34: Loss = 38.5473\nEpoch 35: Loss = 37.7939\nEpoch 36: Loss = 37.9304\nEpoch 37: Loss = 37.7158\nEpoch 38: Loss = 37.1043\nEpoch 39: Loss = 37.2727\nEpoch 40: Loss = 37.1314\nEpoch 41: Loss = 36.5047\nEpoch 42: Loss = 36.1476\nEpoch 43: Loss = 36.0564\nEpoch 44: Loss = 35.8868\nEpoch 45: Loss = 35.4731\nEpoch 46: Loss = 35.1059\nEpoch 47: Loss = 35.0913\nEpoch 48: Loss = 34.5455\nEpoch 49: Loss = 34.8090\nEpoch 50: Loss = 34.4335\nEpoch 51: Loss = 34.1413\nEpoch 52: Loss = 34.2845\nEpoch 53: Loss = 34.4400\nEpoch 54: Loss = 34.0666\nEpoch 55: Loss = 33.7952\nEpoch 56: Loss = 33.3970\nEpoch 57: Loss = 32.9658\nEpoch 58: Loss = 32.8838\nEpoch 59: Loss = 32.6953\nEpoch 60: Loss = 32.5663\nEpoch 61: Loss = 32.4220\nEpoch 62: Loss = 32.3284\nEpoch 63: Loss = 32.0876\nEpoch 64: Loss = 32.0780\nEpoch 65: Loss = 31.8728\nEpoch 66: Loss = 31.3807\nEpoch 67: Loss = 31.0671\nEpoch 68: Loss = 31.3658\nEpoch 69: Loss = 31.2425\nEpoch 70: Loss = 31.3876\nEpoch 71: Loss = 30.7527\nEpoch 72: Loss = 30.3615\nEpoch 73: Loss = 30.3515\nEpoch 74: Loss = 30.3934\nEpoch 75: Loss = 30.1668\nEpoch 76: Loss = 29.8744\nEpoch 77: Loss = 29.6318\nEpoch 78: Loss = 29.8816\nEpoch 79: Loss = 29.6766\nEpoch 80: Loss = 29.6358\nEpoch 81: Loss = 29.5379\nEpoch 82: Loss = 29.0831\nEpoch 83: Loss = 28.7933\nEpoch 84: Loss = 28.7400\nEpoch 85: Loss = 28.6992\nEpoch 86: Loss = 28.2956\nEpoch 87: Loss = 28.1682\nEpoch 88: Loss = 28.5803\nEpoch 89: Loss = 28.5214\nEpoch 90: Loss = 28.3308\nEpoch 91: Loss = 28.0123\nEpoch 92: Loss = 27.8484\nEpoch 93: Loss = 27.6303\nEpoch 94: Loss = 27.6544\nEpoch 95: Loss = 27.4475\nEpoch 96: Loss = 26.9684\nEpoch 97: Loss = 26.8301\nEpoch 98: Loss = 26.9290\nEpoch 99: Loss = 27.0760\nâœ… Model saved!\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# ğŸµ 6. Generate a MIDI file from a melody\n\ndef generate_midi(melody_ids, melody_vocab, filename=\"generated.mid\"):\n    inv_vocab = {v: k for k, v in melody_vocab.items()}\n    pm = pretty_midi.PrettyMIDI()\n    inst = pretty_midi.Instrument(program=0)\n    for i, idx in enumerate(melody_ids):\n        pitch = inv_vocab.get(idx, 60)\n        note = pretty_midi.Note(\n            velocity=100, pitch=pitch, start=i*0.5, end=(i+1)*0.5\n        )\n        inst.notes.append(note)\n    pm.instruments.append(inst)\n    pm.write(filename)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T17:52:31.314521Z","iopub.execute_input":"2025-06-01T17:52:31.314777Z","iopub.status.idle":"2025-06-01T17:52:31.320013Z","shell.execute_reply.started":"2025-06-01T17:52:31.314760Z","shell.execute_reply":"2025-06-01T17:52:31.319340Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# ğŸ¼ 7. Generate new melody from custom chord input\n\ndef sample_logits(logits, temperature=1.0):\n    probs = torch.softmax(logits / temperature, dim=-1)\n    return torch.multinomial(probs, num_samples=1)\n\ndef generate_from_model(model, chord_sequence, melody_vocab, device=\"cpu\", temperature=1.0):\n    model.eval()\n    with torch.no_grad():\n        chords = torch.tensor(chord_sequence).unsqueeze(0).to(device)\n        logits = model(chords).squeeze(0)\n        sampled = [sample_logits(logits[i], temperature).item() for i in range(logits.size(0))]\n        return sampled\n\n# âœ… Load model for inference\nmodel.load_state_dict(torch.load(\"lstm_model.pt\"))\nmodel.eval()\n\n# # ğŸ†• Example: generate a longer melody from a longer chord progression\n# nintendo_intro = [data[\"chord_vocab\"].get(label) for label in [\n#     \"C_major\", \"A_minor\", \"F_major\", \"G_major\",\n#     \"E_minor\", \"D_minor\", \"C_major\", \"A_minor\",\n#     \"F_major\", \"G_major\", \"C_major\", \"A_minor\",\n#     \"F_major\", \"G_major\", \"E_minor\", \"D_minor\",\n# ]]\n\nnintendo_intro = [data[\"chord_vocab\"].get(label) for label in [\n    \"C_major\", \"F_major\", \"G_major\", \"C_major\"\n]]\n\n\n\nnintendo_intro = [c if c is not None else 0 for c in nintendo_intro] + [0] * (64 - 16)\n\ngenerated_ids = generate_from_model(model, nintendo_intro, data[\"melody_vocab\"], temperature=0.8)\ngenerate_midi(generated_ids, data[\"melody_vocab\"], \"generate_4.mid\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-01T17:52:43.713890Z","iopub.execute_input":"2025-06-01T17:52:43.714573Z","iopub.status.idle":"2025-06-01T17:52:43.748665Z","shell.execute_reply.started":"2025-06-01T17:52:43.714550Z","shell.execute_reply":"2025-06-01T17:52:43.747954Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}